# ì›”ê°„ ë°ì´ì½˜ ë°œí™”ìì˜ ê°ì •ì¸ì‹ AI ê²½ì§„ëŒ€íšŒ

<br>

## Performance ğŸ“Š
----

<br>

|model_name| dev macro F1 score | test macro F1 score |
|:--:|:--:|:--:|
| Baseline | 0.4507 | 0.3890 |
| emoBERTa-Base | 0.5901 | 0.4752 |
| emoBERTa-Base, accumulate = 3 | 0.5901 | 0.4705 |
| **emoBERTa-Large** | **0.6627** | **0.5153** |
| CoMPM: roBERTa-Large (default) | 0.5381 | 0.3818 |
| CoMPM: emoBERTa-Large (freeze) | 0.6282 | - |
| CoMPM: emoBERTa-Large (no freeze) | 0.6342 | - |
| CoMPM: emoBERTa-Large (freeze, focal_loss) | 0.6405 | 0.3845 |

<br>

* acculmulate ëŠ” ì´ì „ ë°œí™”ë¥¼ í•¨ê»˜ ë°ì´í„°ë¡œ ë„£ê³ ì, ê°€ë³ê²Œ ì „ì²˜ë¦¬ë¥¼ í•´ì£¼ì—ˆìŠµë‹ˆë‹¤. í˜„ì¬ ë°œí™”ê¹Œì§€ í¬í•¨í•´ì„œ ìµœëŒ€ 3ê°œê¹Œì§€ ê°–ê³  ìˆë„ë¡ í•©ë‹ˆë‹¤. ì´ì „ ë°œí™”ê°€ ì—†ìœ¼ë©´, ì—†ëŠ” ëŒ€ë¡œ ë‘¡ë‹ˆë‹¤.

<br>

## To Do ğŸ“š
----

<br>

- COMET ë°ì´í„° í™œìš©

    + emoBERTa ê¸°ë°˜ìœ¼ë¡œ í™œìš©í•  ì˜ˆì •

<br>

- emoBERTa

    + emoBERTa ë…¼ë¬¸ ì •ë…

<br>

- Graph êµ¬ì¡°ë¥¼ í™œìš©í•´ë³¼ ìˆœ ì—†ì„ê¹Œ?

<br>

- Label Smoothing?

<br>

## Done â­
----

<br>

- Baseline

    + ì½”ë“œ ê°„ê²°í™”

    + EarlyStop ì ìš©

    + AdamW ë³€ê²½

    + AMP ì ìš©

<br>

- ë°ì´í„° ë¶„ì„í•˜ê¸°

    + train / valid ë¹„ìœ¨

    + ëŒ€í™” ê°œìˆ˜ / ë‹´í™” ê°œìˆ˜ ì¸¡ì •

<br>

- [CoMPM](https://github.com/rungjoo/CoMPM)

    + [CoMPM ë…¼ë¬¸ ì •ë…](https://heygeronimo.tistory.com/32)

    + ì½”ë“œ ìˆ˜ì • ë° DACON DATASET ì ìš©

    + ì„±ëŠ¥ ì¸¡ì •

        * whether freeze or not

        * pretrained model: [RoBERTa-Large](https://huggingface.co/roberta-large) / [Emoberta-Large](https://huggingface.co/tae898/emoberta-large?text=I+like+you.+I+love+you)

        * loss: CrossEntropyLoss or Focal Loss



<br>

- [COMET-ATOMIC-2020](https://github.com/allenai/comet-atomic-2020)

    + ëª¨ë¸ë¡œ ì˜ë„, ì¥ì†Œ, ì›ì¸ ë“± ë‹¤ì–‘í•œ ì •ë³´ ì¶”ì¶œ

    + ì´ 51ê°œì˜ relation ì„ ë½‘ì„ ê²ƒì´ë©°, 1ê°œë‹¹ 1ì‹œê°„ì´ ì†Œìš”ë˜ê¸° ë•Œë¬¸ì— 50ì‹œê°„ì´ ì§€ë‚˜ì•¼ ëë‚  ê²ƒ ê°™ë‹¤.
