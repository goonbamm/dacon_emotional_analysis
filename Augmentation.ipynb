{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"collapsed_sections":[],"machine_shape":"hm","authorship_tag":"ABX9TyNV3OgDvaam61jBJN16YAs9"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","gpuClass":"standard"},"cells":[{"cell_type":"markdown","source":["# **COMET-atomic-2020 사용법**\n"],"metadata":{"id":"pjHpDHFU_zyJ"}},{"cell_type":"markdown","source":["#### **Google Drive Mount**"],"metadata":{"id":"Fd1Wf97j_-0M"}},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"bpsu-Cxx-sGh","executionInfo":{"status":"ok","timestamp":1668483829256,"user_tz":-540,"elapsed":22111,"user":{"displayName":"Jiyeol Park","userId":"16780588767623206728"}},"outputId":"56a1eae9-203e-4506-bbaa-a963c23eb6e1"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"markdown","source":["#### **Install and Import**"],"metadata":{"id":"kLVOSaRDAE0d"}},{"cell_type":"code","source":["!pip install transformers"],"metadata":{"id":"_b-Dsd20Nu11","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1668483839170,"user_tz":-540,"elapsed":9927,"user":{"displayName":"Jiyeol Park","userId":"16780588767623206728"}},"outputId":"9bfa6b59-4d49-4a31-a1a2-e198b94ceede"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting transformers\n","  Downloading transformers-4.24.0-py3-none-any.whl (5.5 MB)\n","\u001b[K     |████████████████████████████████| 5.5 MB 4.3 MB/s \n","\u001b[?25hRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (6.0)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.6)\n","Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.13.0)\n","Collecting huggingface-hub<1.0,>=0.10.0\n","  Downloading huggingface_hub-0.10.1-py3-none-any.whl (163 kB)\n","\u001b[K     |████████████████████████████████| 163 kB 97.9 MB/s \n","\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2022.6.2)\n","Collecting tokenizers!=0.11.3,<0.14,>=0.11.1\n","  Downloading tokenizers-0.13.2-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.6 MB)\n","\u001b[K     |████████████████████████████████| 7.6 MB 66.0 MB/s \n","\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.64.1)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.8.0)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.10.0->transformers) (4.1.1)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.9)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.10.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2022.9.24)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n","Installing collected packages: tokenizers, huggingface-hub, transformers\n","Successfully installed huggingface-hub-0.10.1 tokenizers-0.13.2 transformers-4.24.0\n"]}]},{"cell_type":"code","source":["import os\n","import json\n","import torch\n","import argparse\n","\n","import pandas as pd\n","\n","from tqdm import tqdm\n","from pathlib import Path\n","from transformers import AutoModelForSeq2SeqLM, AutoTokenizer"],"metadata":{"id":"-DE4wnqd7lqZ","executionInfo":{"status":"ok","timestamp":1668483843759,"user_tz":-540,"elapsed":4598,"user":{"displayName":"Jiyeol Park","userId":"16780588767623206728"}}},"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":["#### **Device Setting**"],"metadata":{"id":"l2N6dtG2AI4f"}},{"cell_type":"code","source":["device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n","!nvidia-smi"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"n8UTpNdfcZa9","executionInfo":{"status":"ok","timestamp":1668483844702,"user_tz":-540,"elapsed":952,"user":{"displayName":"Jiyeol Park","userId":"16780588767623206728"}},"outputId":"c4d2388d-0135-493b-df7b-4f4fdb5ebada"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["Tue Nov 15 03:44:03 2022       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|                               |                      |               MIG M. |\n","|===============================+======================+======================|\n","|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   42C    P8    10W /  70W |      3MiB / 15109MiB |      0%      Default |\n","|                               |                      |                  N/A |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                                  |\n","|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n","|        ID   ID                                                   Usage      |\n","|=============================================================================|\n","|  No running processes found                                                 |\n","+-----------------------------------------------------------------------------+\n"]}]},{"cell_type":"markdown","source":["#### **Install COMET-ATOMIC2020 with BART**"],"metadata":{"id":"-Y4Gd6T6bMUn"}},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"qx7vUeZ1Y69I","executionInfo":{"status":"ok","timestamp":1668483847059,"user_tz":-540,"elapsed":2366,"user":{"displayName":"Jiyeol Park","userId":"16780588767623206728"}},"outputId":"d3672216-1c84-49d1-d91f-dc073fc1ddca"},"outputs":[{"output_type":"stream","name":"stdout","text":["Cloning into 'comet-atomic-2020'...\n","remote: Enumerating objects: 190, done.\u001b[K\n","remote: Counting objects: 100% (77/77), done.\u001b[K\n","remote: Compressing objects: 100% (38/38), done.\u001b[K\n","remote: Total 190 (delta 56), reused 42 (delta 39), pack-reused 113\u001b[K\n","Receiving objects: 100% (190/190), 7.15 MiB | 6.40 MiB/s, done.\n","Resolving deltas: 100% (74/74), done.\n"]}],"source":["!git clone https://github.com/allenai/comet-atomic-2020.git"]},{"cell_type":"code","source":["%cd /content/comet-atomic-2020/models/comet_atomic2020_bart\n","!pip install -r requirements.txt\n","!bash download_model.sh"],"metadata":{"id":"yWIuGixQLgRt"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!python ./generation_example.py"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"qQAGD_tn77ma","executionInfo":{"status":"ok","timestamp":1668506224213,"user_tz":-540,"elapsed":17124155,"user":{"displayName":"Jiyeol Park","userId":"16780588767623206728"}},"outputId":"6ad6e2ba-e5aa-4514-91f7-62c87d8bdd8e"},"execution_count":31,"outputs":[{"output_type":"stream","name":"stdout","text":["model loading ...\n","model loaded\n","data loading ...\n","data loaded\n","Data Preprocessing with COMET:   0% 0/51 [00:00<?, ?it/s]\n","---- AtLocation processing ----\n","\n","\n","0it [00:00, ?it/s]\u001b[A\n","2644it [00:00, 26434.98it/s]\u001b[A\n","5288it [00:00, 26338.44it/s]\u001b[A\n","9989it [00:00, 26499.53it/s]\n","\n","---- AtLocation completed ----\n","\n","Data Preprocessing with COMET:   2% 1/51 [55:15<46:02:46, 3315.33s/it]\n","---- CapableOf processing ----\n","\n","\n","0it [00:00, ?it/s]\u001b[A\n","2601it [00:00, 26008.35it/s]\u001b[A\n","5300it [00:00, 26580.31it/s]\u001b[A\n","9989it [00:00, 26615.27it/s]\n","\n","---- CapableOf completed ----\n","\n","Data Preprocessing with COMET:   4% 2/51 [1:52:51<46:15:23, 3398.45s/it]\n","---- Causes processing ----\n","\n","\n","0it [00:00, ?it/s]\u001b[A\n","2583it [00:00, 25823.62it/s]\u001b[A\n","5275it [00:00, 26465.94it/s]\u001b[A\n","9989it [00:00, 26464.25it/s]\n","\n","---- Causes completed ----\n","\n","Data Preprocessing with COMET:   6% 3/51 [2:48:07<44:48:20, 3360.43s/it]\n","---- CausesDesire processing ----\n","\n","\n","0it [00:00, ?it/s]\u001b[A\n","2543it [00:00, 25421.24it/s]\u001b[A\n","5216it [00:00, 26187.11it/s]\u001b[A\n","9989it [00:00, 26279.69it/s]\n","\n","---- CausesDesire completed ----\n","\n","Data Preprocessing with COMET:   8% 4/51 [3:43:16<43:36:39, 3340.41s/it]\n","---- CreatedBy processing ----\n","\n","\n","0it [00:00, ?it/s]\u001b[A\n","2595it [00:00, 25940.81it/s]\u001b[A\n","5339it [00:00, 26820.35it/s]\u001b[A\n","9989it [00:00, 26510.10it/s]\n","Data Preprocessing with COMET:   8% 4/51 [4:45:07<55:50:10, 4276.81s/it]\n","Traceback (most recent call last):\n","  File \"./generation_example.py\", line 137, in <module>\n","    results = comet.generate(queries, decode_method='greedy', num_generate=1)\n","  File \"./generation_example.py\", line 51, in generate\n","    num_return_sequences=num_generate,\n","  File \"/usr/local/lib/python3.7/dist-packages/torch/autograd/grad_mode.py\", line 15, in decorate_context\n","    return func(*args, **kwargs)\n","  File \"/usr/local/lib/python3.7/dist-packages/transformers/generation_utils.py\", line 248, in generate\n","    if self.get_output_embeddings() is None:\n","  File \"/usr/local/lib/python3.7/dist-packages/transformers/modeling_bart.py\", line 1068, in get_output_embeddings\n","    return _make_linear_from_emb(self.model.shared)  # make it on the fly\n","  File \"/usr/local/lib/python3.7/dist-packages/transformers/modeling_bart.py\", line 166, in _make_linear_from_emb\n","    lin_layer = nn.Linear(vocab_size, emb_size, bias=False)\n","  File \"/usr/local/lib/python3.7/dist-packages/torch/nn/modules/linear.py\", line 77, in __init__\n","    self.reset_parameters()\n","  File \"/usr/local/lib/python3.7/dist-packages/torch/nn/modules/linear.py\", line 80, in reset_parameters\n","    init.kaiming_uniform_(self.weight, a=math.sqrt(5))\n","  File \"/usr/local/lib/python3.7/dist-packages/torch/nn/init.py\", line 327, in kaiming_uniform_\n","    return tensor.uniform_(-bound, bound)\n","KeyboardInterrupt\n"]}]},{"cell_type":"markdown","source":["## **파일 내용 수정**\n","- 모델을 불러오는 방법을 알아내기 힘들어서 불가피하게 아래 내용을 복사합니다.\n","- 'generate_example.py' 에 붙여 넣으시면 됩니다."],"metadata":{"id":"4VLnH8aJNSoK"}},{"cell_type":"code","source":["\"\"\"\n","import os\n","import json\n","import torch\n","import argparse\n","\n","import pandas as pd\n","\n","from tqdm import tqdm\n","from pathlib import Path\n","from transformers import AutoModelForSeq2SeqLM, AutoTokenizer\n","from utils import calculate_rouge, use_task_specific_params, calculate_bleu_score, trim_batch\n","\n","\n","def chunks(lst, n):\n","    \"\"\"Yield successive n-sized chunks from lst.\"\"\"\n","    for i in range(0, len(lst), n):\n","        yield lst[i : i + n]\n","\n","\n","class Comet:\n","    def __init__(self, model_path):\n","        self.device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n","        self.model = AutoModelForSeq2SeqLM.from_pretrained(model_path).to(self.device)\n","        self.tokenizer = AutoTokenizer.from_pretrained(model_path)\n","        task = \"summarization\"\n","        use_task_specific_params(self.model, task)\n","        self.batch_size = 1\n","        self.decoder_start_token_id = None\n","\n","    def generate(\n","            self, \n","            queries,\n","            decode_method=\"beam\", \n","            num_generate=5, \n","            ):\n","\n","        with torch.no_grad():\n","            examples = queries\n","\n","            decs = []\n","            for batch in list(chunks(examples, self.batch_size)):\n","\n","                batch = self.tokenizer(batch, return_tensors=\"pt\", truncation=True, padding=\"max_length\").to(self.device)\n","                input_ids, attention_mask = trim_batch(**batch, pad_token_id=self.tokenizer.pad_token_id)\n","\n","                summaries = self.model.generate(\n","                    input_ids=input_ids,\n","                    attention_mask=attention_mask,\n","                    decoder_start_token_id=self.decoder_start_token_id,\n","                    num_beams=num_generate,\n","                    num_return_sequences=num_generate,\n","                    )\n","\n","                dec = self.tokenizer.batch_decode(summaries, skip_special_tokens=True, clean_up_tokenization_spaces=False)\n","                decs.append(dec)\n","\n","            return decs\n","\n","\n","all_relations = [\n","    \"AtLocation\",\n","    \"CapableOf\",\n","    \"Causes\",\n","    \"CausesDesire\",\n","    \"CreatedBy\",\n","    \"DefinedAs\",\n","    \"DesireOf\",\n","    \"Desires\",\n","    \"HasA\",\n","    \"HasFirstSubevent\",\n","    \"HasLastSubevent\",\n","    \"HasPainCharacter\",\n","    \"HasPainIntensity\",\n","    \"HasPrerequisite\",\n","    \"HasProperty\",\n","    \"HasSubEvent\",\n","    \"HasSubevent\",\n","    \"HinderedBy\",\n","    \"InheritsFrom\",\n","    \"InstanceOf\",\n","    \"IsA\",\n","    \"LocatedNear\",\n","    \"LocationOfAction\",\n","    \"MadeOf\",\n","    \"MadeUpOf\",\n","    \"MotivatedByGoal\",\n","    \"NotCapableOf\",\n","    \"NotDesires\",\n","    \"NotHasA\",\n","    \"NotHasProperty\",\n","    \"NotIsA\",\n","    \"NotMadeOf\",\n","    \"ObjectUse\",\n","    \"PartOf\",\n","    \"ReceivesAction\",\n","    \"RelatedTo\",\n","    \"SymbolOf\",\n","    \"UsedFor\",\n","    \"isAfter\",\n","    \"isBefore\",\n","    \"isFilledBy\",\n","    \"oEffect\",\n","    \"oReact\",\n","    \"oWant\",\n","    \"xAttr\",\n","    \"xEffect\",\n","    \"xIntent\",\n","    \"xNeed\",\n","    \"xReact\",\n","    \"xReason\",\n","    \"xWant\",\n","    ]\n","\n","if __name__ == \"__main__\":\n","    # sample usage (reproducing AAAI)\n","    print(\"model loading ...\")\n","    comet = Comet(\"./comet-atomic_2020_BART_aaai\")\n","    comet.model.zero_grad()\n","    print(\"model loaded\")\n","\n","    print(\"data loading ...\")\n","    data_path = '/content/drive/MyDrive/dacon_sentiment_analysis/dataset'\n","    data_csv = pd.read_csv(os.path.join(data_path, 'train.csv'))\n","\n","    print('data loaded')\n","\n","    queries = []\n","\n","    for rel in tqdm(all_relations, desc=f'Data Preprocessing with COMET'):\n","        print(f'\\n---- {rel} processing ----\\n')\n","        queries = []\n","\n","        for i, row in tqdm(data_csv.iterrows()):\n","            query = '{} {}'.format(row['Utterance'], rel)\n","            queries.append(query)\n","\n","        results = comet.generate(queries, decode_method='greedy', num_generate=1)\n","        results = [r[0] for r in results]\n","\n","        data_csv[rel] = results\n","\n","        print(f'\\n---- {rel} completed ----\\n')\n","\n","    data_csv.to_csv('./comet_train.csv', index=False)\n","\"\"\""],"metadata":{"id":"JjOt7ifFoiRp"},"execution_count":null,"outputs":[]}]}